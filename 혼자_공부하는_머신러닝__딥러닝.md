[[머신러닝]][[3000 Study]][[3100 인공지능]][[3110 머신러닝]][[3120 딥러닝]]
## 03-3. 특성 공학과 규제
#### 키워드 : 다중 회귀, 특성 공학, 릿지, 라쏘, 하이퍼파라미터

##### 문제 정의
- 몸통 길이와 길이를 제곱해서 선형 회귀 모델을 훈련했는데 아직도 과소적합이라고??
- 그래서 너 농어의 길이만 사용한거야? 다른 데이터는 없어?
- 어머나 이럴수가!! 높이와 두께 데이터도 있다니?? 역시 데이터는 다 사용해야 돼
	- 그 이유가 선형 회귀는 특성이 많을수록 더 좋은 효과를 낸다구
	- 이번에는 직접 만들지 말고 PolynomialFeatures 클래스 사용해봐
		- PolynomialFeatures가 뭔데요?
			- 주어진 특성(feature)을 다항식으로 변환해주는데 사용
			- 다항식 특성을 추가함으로써 선형 회귀와 같은 선형 모델을 사용하여 비선형 관계를 모델링

##### 다중 회귀
- 여러 개의 특성을 사용한 선형 회귀
- ![[Pasted image 20240319225326.png]]
- 아니 1개의 특성을 사용하면 직선을 학습하는 건 알아
- 2개의 특성은 평면을 학습하는 것도 알아
- 3개의 특성을 사용하면 어떻게 해야 돼?
	- 3차원으로 넘어가야 하는데 우리가 이걸 상상할 수 있어? 아니 못해
##### 특성 공학
- 기존의 특성을 사용해 새로운 특성을 뽑아내는 작업
- ex) 농어 길이 X 농어 높이
###### 그러면 여기서 사용하는 특성은 몇 개인데?
- 총 3개야(농어의 길이, 농어의 높이, 농어의 두께)
##### 데이터 준비
- 일단 농어의 특성이 3개인데 그거 언제 데이터 복사해서 붙여넣을 건데? 나는 비효율적인 거 굉장히 싫어해!
- 편안한 방법 없어? => 그냥 나 인터넷에서 데이터 다운로드에서 사용하고 싶어!
- 넘파이에는 이런 기능 있어? => 아니 없어 => 그럼? => 판다스가 그거 지원해준데
- 아니 판다스는 또 뭔데?
	- 그냥 유명하고 많이 쓰는 데이터 분석 라이브러리인데, 데이터프레임을 사용한데
	- 아니 또 데이터프레임은 뭔데?
		- ![[Pasted image 20240319225410.png]]
		- 행과 열로 이루어진 테이블 형식의 데이터 구조
		- 엑셀 스프레드시트나 SQL 데이터베이스의 테이블과 유사한 구조
	- 그럼 판다스는 어떻게 사용하는데?
		- read_csv()함수에 주소를 넣어 주면 돼
		- to_numpy()로 넘파이 배열로 바꾸면 돼
##### 사이킷런의 변환기
- 아니 변환기는 또 뭐야?
	- 특성을 만들거나 전처리하는 클래스를 말한데
	- 그 중에서 PolynomialFeatures 클래스를 사용할거야
	- 이거 사이킷런에 어차피 포함되어 있으니까 불러오기만 하면 돼
- 그럼 2개의 특성 2와 3으로 이루어진 샘플 하나에 적용해볼게
	- 우리가 여기서 쓸 메서드는 fit(), transform() 두 가지야
		- 그럼 fit()은 뭔데?
			- 새롭게 만들 특성 조합을 찾아
		- transform()은 뭐지?
			- 실제로 데이터를 변환해
	- 여기서 중요한 건 **입력 데이터를 변환하는데 타깃 데이터 필요x** 라는 사실이야
	- 그럼 어떻게 숫자가 나오는데?
		- 1,2,3,4,6,9 이렇게 나와
			- ![[Pasted image 20240319225441.png]]
			- 근데 나머지는 알겠는데 1은 어떻게 나오는거야?
				- 선형 방정식의 절편을 항상 값이 1인 특성과 곱해지는 계수야
				- 그래서 특성이 (길이, 높이, 두께, 1)로 구성되는 거야
				- 근데 사이킷런의 선형 모델은 자동으로 저련을 추가하니까 저거 필요없어
					- 이걸 없애기 위해서 include_bias=False를 지정해볼게
						- 근데 꼭 이거 지정해야 돼?
							- 자동으로 무시하기는 하는데 그냥 명시적으로 지정한거야
- 이제 그럼 이걸 적용해볼게
	- train_input에 적용하고 변환한 데이터를 train_poly에 저장해서 배열의 크기 확인해볼게
	- (42,9)가 나왔고 9개의 특성이 만들어졌네?
		- ![[Pasted image 20240319225456.png]]
		- ('x0', 'x1', 'x2', 'x0^2', 'x0 x1', 'x0 x2', 'x1^2', 'x1 x2', 'x2^2')
	- 테스트 세트도 변환하려고 하는데 이거 꼭 훈련 세트에 적용했던 변환기로 해야 돼?
		- 충분히 궁금할 수 있지. fit() 메서드에서 만들 특성의 조합을 준비하기만 하고 통계의 값을 별도로 구하지 않아서 따로 변환해도 되긴 해
		- 근데 이런 습관을 들여야지 나중에 다른 클래스를 사용해서 진행할 때 헷갈리지 않을 수 있어
##### 다중 회귀 모델 훈련하기
- ![[Pasted image 20240319225535.png]]
- ![[Pasted image 20240319225542.png]]
- 테스트 세트 점수가 높아지지는 않았지만 농어의 길이만 사용했을 때 나타났던 **과소적합** 문제는 나타나지 않아서 좋다
- 근데 갑자기 이런 생각이 드는데, 특성이 늘어나면 선형 회귀의 능력이 매우 강해진다고 했는데 특성을 더 많게 하면 어떻게 되지?
	- 그냥 degree 매개변수 사용해서 3제곱, 4제곱 항 넣으면 돼
	- 근데 왜 테스트 세트의 점수가 음수야? 이게 무슨 일이야??
		- 물론 특성의 개수를 늘리면 선형 모델이 강력해져서 훈련 세트에 대해서는 완벽하게 수행할 수 있지만 이렇게 되면 훈련 세트에 **과대적합**되어서 테스트에서는 점수가 나오지는 않는거야
		- 우리가 좀 생각해보자. 여기서 쓰인 샘플의 개수가 42개인데 특성이 55개면 어떨 것 같아? 너무 쓸데없이 많아 보이지 않아?
		- ![[Pasted image 20240319225603.png]]
		- ![[Pasted image 20240319225626.png]]
		- ![[Pasted image 20240319225643.png]]
		- 그러면 특성을 줄여보자!
##### 규제
- ![[Pasted image 20240319225659.png]]
- 아까 훈련 세트에 과대적합 되었다고 말했는데 과도하게 학습하지 못하도록 막는 것을 의미
- 선형 회귀 모델의 경우 특성에 곱해지는 계수의 크기를 작게 만드는거야
- 그래서 55개의 특성으로 훈련한 선형 회귀 모델을 좀 규제해볼게
	- 근데 2장에서 우리가 공부했었는데 특성의 스케일이 정규화되지 않으면 어떤 일이 벌어지는지 봤었지? 그래서 정규화는 꼭 필요해
	- 2장에서는 직접 구했었잖아? 근데 사이킷런에서 StandardScaler 클래스가 있어서 이걸 사용해볼게
		- 아니 또 StandardScaler 클래스는 뭔데?
			- 전처리(preprocessing) 도구 중 하나
			- 데이터의 특성(feature)을 평균이 0이고 표준편차가 1이 되도록 스케일링해주는 역할
			- 각 특성의 값 범위를 비슷하게 만들어주고, 모델의 성능을 향상
				- 각 특성별로 평균을 계산합니다.
				- 각 특성별로 표준편차를 계산합니다.
				- 각 특성의 값에서 평균을 빼고, 표준편차로 나누어 스케일링을 수행합니다.
- 그럼 StandardScaler 클래스의 객체 ss를 초기화하고 PolynomialFeatures 클래스로 만든 train_poly를 사용해 이 객체를 훈련할게
	- 아니 근데 왜 객체 ss를 초기화해야 돼?
		- 스케일링을 수행하기 위한 파라미터들을 계산하고 설정하기 위해서야
		- 데이터의 특성(feature)에 따라 계산되며, 각 특성별로 평균과 표준편차를 계산하여 이를 이용해 스케일링을 수행하지
		- StandardScaler 객체를 초기화하지 않고 바로 데이터를 스케일링하는 것은 스케일링에 필요한 평균과 표준편차를 알 수 없기 때문에 불가능하기 때문이야
	- 여기서 훈련할 때 꼭 **훈련 세트로 학습한 변환기**를 사용해 테스트 세트를 변환해야 돼
- 선형 회귀 모델에 규제를 추가한 모델에는 뭐가 있어?
	- **릿지**와 **라쏘**가 있어
		- 그럼 두 가지는 뭐가 다른데?
			- 간단하게 말하면 릿지는 계수를 제곱한 값을 기준으로 규제를 적용해
			- 반면에 라쏘는 계수의 절댓값을 기준으로 규제를 적용해
##### 릿지 회귀
- 모델 객체 만들고 fit() 메서드에서 훈련하고 score() 메서드에서 평가해보자
- ![[Pasted image 20240319225725.png]]
- ![[Pasted image 20240319225739.png]]
- 테스트 점수가 정상으로 돌아왔네? 역시 규제의 힘인가??
###### 규제의 강도 조절하는 방법
- 릿지랑 라쏘 모델 사용할 때 규제의 양을 임의로 조절할 수 있다는 사실이야
	- 그러면 어떻게 조절하지?
		- 모델 객체를 만들 때 alpha 매개변수로 규제의 강도를 조절하면 돼
			- alpha 값이 크면 규제 강도가 커져서 과소적합 되도록 유도해
			- alpha 값이 작으면 선형 회귀 모델과 유사해져서 과대적합될 수 있어
				- alpha 값은 학습하는 값이야?
					- 여기서 하이퍼파라미터의 개념이 등장해
##### 하이퍼파라미터
- 머신러닝 모델이 학습할 수 없고 사람이 알려줘야 하는 파라미터
- 머신러닝 라이브러리에서 클래스와 메서드의 매개변수로 표현돼

###### 적절한 alpha 값 찾는 방법
=> 첫 번째 방법 : **그리드 서치(Grid Search)를 사용한 교차 검증(Cross-validation):**
- 그리드 서치는 주어진 범위 내에서 여러 후보 alpha 값들을 시도하고, 교차 검증을 통해 각 alpha 값의 성능을 평가하는 방법이야
- 일반적으로는 훈련 데이터를 여러 개의 fold로 나눈 후, 각 fold를 사용하여 모델을 훈련하고 다른 fold를 사용하여 성능을 평가하고 이 과정을 반복하여 모든 fold에 대한 성능을 평균하여 모델의 성능을 측정해
- 그리드 서치를 통해 최적의 alpha 값을 선택할 수 있어.

=> 책에서 알려준 방법 : **alpha 값에 대한 R^2 값의 그래프**를 그려서 훈련 세트와 테스트 세트의 점수가 가장 가까운 지점을 찾으면 돼
- 맷플롯립을 임포트하고 alpha 값을 바꿀 때마다 score() 메서드의 결과를 저장할 리스트를 만들어보자
- alpha 값을 0.001에서 100까지 10배씩 늘려가면서 훈련하고 점수를 파이썬 리스트에 저장해보자
	- 근데 6개의 값을 동일한 간격으로 나타내기 위해서 로그 함수로 바꾸어 지수로 표현할거야
		- ex) 0.001=-3, 0.01=-2
	- ![[Pasted image 20240319225814.png]]
	- 왼쪽을 보면 훈련 세트에는 잘 맞고 테스트 세트에는 형편없는 과대적합의 모습이 보이지
	- 오른쪽은 둘 다 점수가 낮아지는 과소적합의 모습이 보이지 않아?
- 그럼 적절한 alpha 값은 -1이고 이건 즉 0.1이라고 볼 수 있으니까 이걸로 최종 모델을 훈련할게
- ![[Pasted image 20240319225824.png]]
##### 라쏘 회귀
- ![[Pasted image 20240319225846.png]]
- ![[Pasted image 20240319225853.png]]
- 과대적합을 잘 억제한 결과를 보여주는 걸?
- 테스트 점수도 릿지만큼 좋고 alpha 매개변수로 릿지 모델처럼 규제의 강도도 조절할 수 있어
- 아니 근데 경고 뜨는데 이거 맞아?
	- 훈련할 때 ConvergenceWarning이란 경고 뜰 수 있어 왜 그러냐면 라쏘 모델 자체가 최적의 계수를 찾기 위해 반복적인 계산을 해
	- 그런데 지정한 반복 횟수가 부족할 때 이런 경고가 발생할 수 있어
	- 그래서 하는 작업이 max_iter 매개변수의 값을 좀 크게 지정하는 거야
- ![[Pasted image 20240319225903.png]]
- 왼쪽은 과대적합, 오른쪽은 점수가 좁혀지면서 가장 오른쪽으로 가면 점수가 떨어지는 과소적합이 발생하는데?
- 최적의 alpha 값은 1이고 즉 10이니까 이 값으로 다시 모델을 훈련해보자
- ![[Pasted image 20240319225911.png]]
- 근데 라쏘 모델은 계수 값을 아예 0으로 만들 수 있다고 했는데 이건 무슨 말이야?
	- 우선 라쏘 모델의 계수는 coef_속성에 들어있어
	- np.sum()함수를 사용해서 찾아볼까?
		- 아니 또 이번에 np.sum()함수는 뭐야?
			- 배열을 모두 더한 값을 반환하는데 넘파이 배열에 비교 연산자 사용하면 각 원소는 True나 False가 되는데 np.sum()함수는 True=1, False=0으로 인식해서 비교 연산자에 맞는 원소 개수를 셀 수 있겠지?
	